# <center> UniSep: Universal Target Audio Separation with Language Models at Scale </center>

<center> anonymous </center>


## Abstract
Universal target audio separation aims to separate target audio from an arbitrary mix. However, its potential remains to be further explored: Many models are restricted to specific domains and the maximum number of sources. Moreover, mainstream regression models map different sources into high-dimensional space, which may result in quality loss and interference with other sources. In this paper, we present universal target audio separation (UniSep) with language models. Firstly, we extract discrete tokens and employ language models for separation, effectively enhancing the listening quality. Secondly, we propose a novel pre-training strategy to utilize large-scale audio data, which reducing the efforts of large-scale data simulation. For the first time, we demonstrate the effectiveness of \textit{scaling law} in audio separation task: we use a large-scale data, including speech, music and sound events, to train a universal target audio separation model that is not limited to a specific domain. 


## Samples

